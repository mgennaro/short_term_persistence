{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Notebook to study short term persistence from multiple exposures in a single visit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob, os, shutil, pickle, bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sigmaclip\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import gammaincc, gamma\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import histogram\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The project dir \n",
    "pdir = '/user/gennaro/Functional_work/WFC3_persistence/py_progs/short_term_persistence/'\n",
    "\n",
    "#The mosaic dir\n",
    "mdir = pdir+'/Mosaic_hi_res_folder/'\n",
    "\n",
    "#The dir to save/load the Persistence curves dataframes\n",
    "sdir = pdir+'PD_dataframes_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Single and double exponential models to be fitted to the data\n",
    "\n",
    "def decay1(t,a1,t1):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1\n",
    "\n",
    "def intdec1(t,a1,t1):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td)\n",
    "    \n",
    "def decay2(t,a1,t1,a2,t2):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    e2 = a2*np.exp(-t/t2)\n",
    "    return e1+e2\n",
    "\n",
    "def intdec2(t,a1,t1,a2,t2):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k1,k2  = -a1*t1, - a2*t2\n",
    "    \n",
    "    return k1*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) + k2*(np.exp(-tu/t2)-np.exp(-td/t2))/(tu-td)\n",
    "\n",
    "#Single exponential models plus a constant\n",
    "\n",
    "def intdec1_plusconst(t,a1,t1,q):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) +q\n",
    "\n",
    "def dec1_plusconst(t,a1,t1,q):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1+q\n",
    "\n",
    "\n",
    "#Shifted power law model\n",
    "\n",
    "def shpwl(t,t0,A,index):\n",
    "    return A * ((t+t0)/1000)**index\n",
    "\n",
    "def intshpwl(t,t0,A,index):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "\n",
    "    if (index == -1.):\n",
    "        return A*np.log( (tu+t0)/(td+t0) )\n",
    "    else:\n",
    "        return A/(1+index) * ( ((tu+t0)/1000)**(1+index) - ((td+t0)/1000)**(1+index) )/(tu-td)\n",
    "    \n",
    "    \n",
    "#Schechter like model\n",
    "\n",
    "def schechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "    return phi*(x**alpha)*np.exp(-x)\n",
    "\n",
    "def intschechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "\n",
    "    tu = x[1:]\n",
    "    td = x[:-1]\n",
    "\n",
    "    g1 = gammaincc(alpha+1,td)\n",
    "    g2 = gammaincc(alpha+1,tu)\n",
    "    \n",
    "    diff = gamma(alpha+1)*(g1-g2)\n",
    "    \n",
    "    return phi*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Geometric median calculation function\n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1, D\n",
    "\n",
    "        y = y1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read files, make sure they are sorted by EXPSTART\n",
    "\n",
    "sflts= []\n",
    "\n",
    "for vis in ['1','2','3']:\n",
    "    wdir = pdir+'/14016_data/Visit0'+vis+'/'\n",
    "    flts = glob.glob(wdir+'*_flt.fits')\n",
    "    print('***************')\n",
    "    starttimes = []\n",
    "    endtimes   = []\n",
    "    imagetypes = []\n",
    "    for flt in flts:\n",
    "        starttimes.append(fits.getheader(flt,0)['EXPSTART'])\n",
    "        endtimes.append(fits.getheader(flt,0)['EXPEND'])\n",
    "        imagetypes.append(fits.getheader(flt,0)['IMAGETYP'])\n",
    "    \n",
    "    ii = np.argsort(starttimes)\n",
    "    for jj in range(len(flts)):\n",
    "        print(starttimes[ii[jj]],endtimes[ii[jj]],(starttimes[ii[jj]]-endtimes[ii[jj]])*24*3600,imagetypes[ii[jj]],flts[ii[jj]])\n",
    "\n",
    "\n",
    "    sflts.append([flts[i] for i in ii])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose which visit to work on\n",
    "\n",
    "visit_index = 0\n",
    "vsflts = sflts[visit_index]\n",
    "\n",
    "# If in a hurry, shorten the list for faster analysis\n",
    "\n",
    "#vsflts = vsflts[0:10]\n",
    "\n",
    "#plot all exposures multiple times for visualization of the selected pixels\n",
    "\n",
    "sf=1.5\n",
    "fig = plt.figure(figsize=(sf*len(vsflts),sf*len(vsflts)))\n",
    "\n",
    "ax = []\n",
    "for i,flt in enumerate(vsflts):\n",
    "    im = fits.getdata(flt)\n",
    "    c, low, upp = sigmaclip(im, 2.5,3)\n",
    "    mn = np.amin(c)\n",
    "    print(flt,'clipped mean: ',mn)\n",
    "    j = -1\n",
    "    while j < i: \n",
    "        j+=1\n",
    "        ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1+i))\n",
    "        ax[-1].imshow(np.log10(im-mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "        ax[-1].set_title(flt[-18:-9],fontsize=6)\n",
    "        ax[-1].get_xaxis().set_ticks([])\n",
    "        ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "        \n",
    "# Read the mosaic file and plot it\n",
    "\n",
    "plt.tight_layout()\n",
    "mosaic = fits.open(mdir+'/F140W_Mosaic_WFC3_IR_drz.fits')\n",
    "\n",
    "ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1))\n",
    "\n",
    "pos1 = ax[-1].get_position() # get the original position \n",
    "pos2 = [pos1.x0, pos1.y0,  pos1.width * len(vsflts)/2., pos1.height * len(vsflts)/2.] \n",
    "ax[-1].set_position(pos2) # set a new position\n",
    "ax[-1].get_xaxis().set_ticks([])\n",
    "ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "c, low, upp = sigmaclip(mosaic[1].data[np.where(np.isfinite(mosaic[1].data))], 2.5,3)\n",
    "mn = np.amin(c)\n",
    "im = ax[-1].imshow(np.log10(mosaic[1].data-mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "ax[-1].set_title('Drizzled \\n mosaic',fontsize=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create the wcs objects for the AD mosaic and flts \n",
    "\n",
    "w_mosaic = WCS(mosaic[1].header)\n",
    "\n",
    "w_vsflts = []\n",
    "for vsflt in vsflts:\n",
    "    w_vsflts.append(WCS(fits.getheader(vsflt,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes the vsflts list, the current flt that is being used as stimulus\n",
    "# and looks for all the pixels with valid stimulus values AND that have valid ramps (i.e. no source, only sky)\n",
    "# in the following exposures AND that where not stimulated more than 10% of the current stimulus in \n",
    "# ANY past exposure\n",
    "\n",
    "def find_ramps(istim,flts,lev_u,lev_d):\n",
    "    \n",
    "    stimdata  = fits.getdata(flts[istim])\n",
    "    istimgood = (stimdata > lev_d) & (stimdata < lev_u)  \n",
    "    print('Pixels with potentially right stimuli:',np.sum(istimgood) )\n",
    "\n",
    "    \n",
    "    for i,pflt in enumerate(flts[0:istim]):\n",
    "        persdata = fits.getdata(pflt)\n",
    "        if (fits.getheader(pflt,0)['IMAGETYP'] == 'EXT'):  \n",
    "            #msky = np.nanmean(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            #ssky = np.nanstd(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            #istimgood = istimgood & (persdata <msky+1*ssky) & (persdata >msky-1*ssky)    \n",
    "            istimgood = istimgood & (persdata < 0.1*stimdata)  \n",
    "\n",
    "            \n",
    "    print('Pixels with really right stimuli:',np.sum(istimgood) )\n",
    "    \n",
    "    \n",
    "    icount    = np.zeros_like(stimdata,dtype=np.int_)\n",
    "    iprev     = istimgood\n",
    "    for i,pflt in enumerate(flts[istim+1:]):\n",
    "    \n",
    "        persdata = fits.getdata(pflt)\n",
    "        \n",
    "        if (fits.getheader(pflt,0)['IMAGETYP'] == 'EXT'):  \n",
    "            msky = np.nanmean(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            ssky = np.nanstd(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            iskycurr = (persdata <msky+1*ssky) & (persdata >msky-1*ssky)    \n",
    "        \n",
    "        elif (fits.getheader(pflt,0)['IMAGETYP'] == 'DARK'):\n",
    "            iskycurr = np.ones_like(persdata,dtype=np.bool_)\n",
    "        else:\n",
    "            print('Wrong image type')\n",
    "            assert False\n",
    "        \n",
    "        igood = istimgood & iskycurr & iprev\n",
    "        iprev = igood\n",
    "        \n",
    "        icount[igood] += 1\n",
    "\n",
    "        print('Pixels with ramps extending for at least',i+1,' exposures:', igood.sum())\n",
    "        \n",
    "        if (np.sum(igood) == 0):\n",
    "            break\n",
    "       \n",
    "          \n",
    "    return icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dedfine a function to get the sky value in the cureent flt pixel, but measured form the AD mosaic\n",
    "\n",
    "def getskyfrommosaic(wcsAD, wcsFLT, x, y, dxgrid, dygrid, skyrad_o,skyrad_i,drz_fin,mask_sky_contam,mosaic):\n",
    "\n",
    "    coords = wcsAD.all_world2pix(wcsFLT.all_pix2world(np.array([[x,y]],dtype=np.float_),0),0) \n",
    "    dx = coords[0,0]\n",
    "    dy = coords[0,1]\n",
    "    \n",
    "    dst = np.sqrt((dxgrid-dx)**2 + (dygrid-dy)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i) & drz_fin & mask_sky_contam \n",
    "    skyarr = mosaic[1].data[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "# Similar but for darks\n",
    "\n",
    "def getbackgroundfordarks (x, y, xgrid, ygrid, skyrad_o,skyrad_i, fltdata):\n",
    "\n",
    "    dst = np.sqrt((xgrid-x)**2 + (ygrid-y)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i)\n",
    "    skyarr = fltdata[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define the stimuli e-/s level to identify the ramps\n",
    "\n",
    "lev_u = np.inf\n",
    "lev_d = 1e4\n",
    "\n",
    "# Define the pixel grid (to trasform indices in x,y positions)\n",
    "xgrid,ygrid = np.meshgrid( np.arange(fits.getdata(vsflts[0],1).shape[1]) ,np.arange(fits.getdata(vsflts[0],1).shape[0]))\n",
    "dxgrid,dygrid = np.meshgrid( np.arange(mosaic[1].data.shape[1]) ,np.arange(mosaic[1].data.shape[0]))\n",
    "\n",
    "drz_fin = np.isfinite(mosaic[1].data)\n",
    "\n",
    "msky_d = np.nanmean(sigmaclip(mosaic[1].data[drz_fin],2.5,2.5)[0])\n",
    "ssky_d = np.nanstd(sigmaclip(mosaic[1].data[drz_fin],2.5,2.5)[0])\n",
    "mask_sky_contam = (mosaic[1].data <msky_d+3*ssky_d) & (mosaic[1].data >msky_d-3*ssky_d)\n",
    "\n",
    "skyrad_o = 25\n",
    "skyrad_i = 15\n",
    "\n",
    "# Open all the imas and put them in a list\n",
    "\n",
    "imas = []\n",
    "flts = []\n",
    "\n",
    "for vsflt in vsflts:\n",
    "    imas.append(fits.open(vsflt.replace('_flt','_ima')))\n",
    "    flts.append(fits.open(vsflt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The dataframe that will host the ramps\n",
    "\n",
    "dfl = []\n",
    "\n",
    "for istim,stim in enumerate(vsflts[:-1]):\n",
    "\n",
    "    print('**********************')\n",
    "    print('Doing: ',stim)\n",
    "\n",
    "    icount    = find_ramps(istim,vsflts,lev_u,lev_d)\n",
    "    tendMJD   = flts[istim][0].header['EXPEND']\n",
    "    stimdata  = flts[istim][1].data\n",
    "    \n",
    "    nz     = np.nonzero(icount)    \n",
    "    nnexts = icount[nz]\n",
    "    \n",
    "    print('Appending to list')  \n",
    "    count = 0\n",
    "    for nz0,nz1,nnext in zip(nz[0],nz[1],nnexts):\n",
    "        count=count+1\n",
    "        if( (count%100)==1):\n",
    "            print(count)\n",
    "           \n",
    "        for j in range(1,nnext+1,1):\n",
    "\n",
    "            #Get the sky from the drizzled image\n",
    "            imtyp = flts[istim+j][0].header['IMAGETYP']\n",
    "            \n",
    "            if(imtyp == 'EXT'):\n",
    "                skyhere = getskyfrommosaic(w_mosaic, w_vsflts[istim+j], nz1, nz0, dxgrid, dygrid, skyrad_o,skyrad_i,drz_fin,mask_sky_contam,mosaic)\n",
    "            elif(imtyp == 'DARK'):\n",
    "                skyhere = getbackgroundfordarks(nz1, nz0, xgrid, ygrid, skyrad_o,skyrad_i, flts[istim+j][1].data)\n",
    "            else:\n",
    "                print('Wrong image type')\n",
    "                assert False\n",
    "\n",
    "            \n",
    "            offset = (imas[istim+j][0].header['EXPSTART'] - tendMJD)*24.*60*60\n",
    "            \n",
    "            nsamp = imas[istim+j][0].header['NSAMP']\n",
    "            for k in range(nsamp-1):\n",
    "                \n",
    "                te = imas[istim+j]['TIME',k+1].header['PIXVALUE']\n",
    "                ts = imas[istim+j]['TIME',k+2].header['PIXVALUE']\n",
    "\n",
    "                tfromstim = te + offset\n",
    "\n",
    "                tdenom = te - ts  \n",
    "                meancurr  = ((imas[istim+j]['SCI',k+1].data[5:-5,5:-5])[nz0,nz1]*te -\n",
    "                             (imas[istim+j]['SCI',k+2].data[5:-5,5:-5])[nz0,nz1]*ts\n",
    "                            )/tdenom\n",
    "\n",
    "                stdvcurr  = np.sqrt(np.sum(np.square([(imas[istim+j]['ERR',k+1].data[5:-5,5:-5])[nz0,nz1]*te,\n",
    "                                                      (imas[istim+j]['ERR',k+2].data[5:-5,5:-5])[nz0,nz1]*ts\n",
    "                                                     ]\n",
    "                                                    )\n",
    "                                          )\n",
    "                                    )/tdenom\n",
    "                \n",
    "\n",
    "                dfl.append([stimdata[nz0,nz1],nz1,nz0,tfromstim,tdenom,nsamp-k-1,nsamp,meancurr,stdvcurr,skyhere,istim,istim+j])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dfl,columns=['Stim','xpix','ypix','tfromstim','deltat','Read index','NSAMP','meancurr','stdvcurr','ADsky','Ind_stim','Ind_pers'])\n",
    "#df[df.xpix == 711]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with bz2.BZ2File(sdir+'Test_DF.pbz2', 'w') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gBMs    =   [np.ones(len(df),dtype=np.bool_)]\n",
    "gBMs.append( (df['Ind_pers'] != 7) )\n",
    "gBMs.append( (df['Ind_pers'] != 7) & (df['Read index'] != 1) )\n",
    "gBMs.append( (df['Ind_pers'] >= 7) & (df['Read index'] != 1) )\n",
    "gBMs.append( (df['Ind_pers'] > 7) & (df['Read index'] != 1) )\n",
    "gBMs.append( (df['Ind_pers'] < 7) & (df['Read index'] != 1) )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,6*len(gBMs)))\n",
    "ax = []\n",
    "\n",
    "for i,gBM in enumerate(gBMs):\n",
    "\n",
    "    df2 = df[gBM]\n",
    "\n",
    "    ax.append(fig.add_subplot(len(gBMs),2,1+i*2))\n",
    "    ax.append(fig.add_subplot(len(gBMs),2,2+i*2))\n",
    "        \n",
    "    ax[-2].scatter(df2['tfromstim'],df2['meancurr']-df2['ADsky'],s=2,alpha=0.7)\n",
    "    ax[-1].scatter(df2['tfromstim'],df2['meancurr']-df2['ADsky'],s=2,alpha=0.7)\n",
    "\n",
    "    step = 25.\n",
    "    tmin = np.min(df2['tfromstim'].values)\n",
    "    tmax = np.max(df2['tfromstim'].values)\n",
    "\n",
    "    tmed   = []\n",
    "    medsig = []\n",
    "\n",
    "    while tmin <= tmax:\n",
    "\n",
    "        BM =  (df2['tfromstim'].values > tmin-step/2.) & (df2['tfromstim'].values <= (tmin+ step/2.))\n",
    "        tmin += step\n",
    "        if (np.sum(BM) > 3):\n",
    "            tmed.append(np.median(df2['tfromstim'][BM]))\n",
    "            medsig.append(np.nanmedian(sigmaclip((df2['meancurr'][BM].values-df2['ADsky'][BM].values),2.5,2.5)[0]))\n",
    "    \n",
    "    ax[-2].plot(tmed,medsig,c='r')\n",
    "    ax[-1].plot(tmed,medsig,c='r')               \n",
    "    \n",
    "    ax[-1].set_xscale('log')\n",
    "    ax[-1].set_yscale('log')\n",
    "    ax[-1].set_ylim(0.01,30)\n",
    "    ax[-2].set_ylim(-20,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gstims = np.unique(df['Ind_stim'] )\n",
    "\n",
    "fig = plt.figure(figsize=(15,4*gstims.size))\n",
    "\n",
    "ax = []\n",
    "\n",
    "for j,i in enumerate(gstims):\n",
    "    gBMh = (df['Ind_stim'] == i) & (df['Ind_pers'] != 7) & (df['Read index'] != 1)\n",
    "    \n",
    "    \n",
    "    if (np.sum(gBMh) > 0):\n",
    "        df2 = df[gBMh]\n",
    "        ax.append(fig.add_subplot(gstims.size,2,j*2+1))\n",
    "        ax.append(fig.add_subplot(gstims.size,2,j*2+2))\n",
    "\n",
    "        ax[-2].scatter(df2.tfromstim,df2.meancurr-df2.ADsky,s=2,alpha=0.7)\n",
    "        ax[-1].scatter(df2.tfromstim,df2.meancurr-df2.ADsky,s=2,alpha=0.7)\n",
    "\n",
    "        tmedh = []\n",
    "        medsigh= []\n",
    "        tmin = np.min(df2.tfromstim.values)\n",
    "        tmax = np.max(df2.tfromstim.values)\n",
    "\n",
    "        while tmin <= tmax:\n",
    "    \n",
    "            BM =  (df2.tfromstim.values > tmin-step/2.) & (df2.tfromstim.values <= (tmin+ step/2.))\n",
    "            tmin += step\n",
    "            if (np.sum(BM) > 3):\n",
    "                tmedh.append(np.median(df2[BM].tfromstim))\n",
    "                medsigh.append(np.nanmedian(sigmaclip((df2[BM].meancurr.values-df2[BM].ADsky.values),2.5,2.5)[0]))\n",
    "    \n",
    "        ax[-2].plot(tmed,medsig,c='r')\n",
    "        ax[-1].plot(tmed,medsig,c='r')\n",
    "        ax[-2].plot(tmedh,medsigh,c='orange')\n",
    "        ax[-1].plot(tmedh,medsigh,c='orange')\n",
    "    else:\n",
    "        ax[-2].plot(tmed,medsig,c='r')\n",
    "        ax[-1].plot(tmed,medsig,c='r')\n",
    "  \n",
    "    ax[-1].set_xscale('log')\n",
    "    ax[-1].set_yscale('log')\n",
    "    ax[-1].set_ylim(0.01,30)\n",
    "    ax[-2].set_ylim(-20,30)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
