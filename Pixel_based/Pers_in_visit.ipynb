{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Notebook to study short term persistence from multiple exposures in a single visit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob, os, shutil, pickle, bz2, gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sigmaclip\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import gammaincc, gamma\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import histogram\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The project dir \n",
    "pdir = '/user/gennaro/Functional_work/WFC3_persistence/py_progs/short_term_persistence/'\n",
    "\n",
    "#The mosaic dir\n",
    "mdir = pdir+'/Mosaic_hi_res_folder/'\n",
    "\n",
    "#The dir to save/load the Persistence curves dataframes\n",
    "sdir = pdir+'/PD_dataframes_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Single and double exponential models to be fitted to the data\n",
    "\n",
    "def decay1(t,a1,t1):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1\n",
    "\n",
    "def intdec1(t,a1,t1):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td)\n",
    "    \n",
    "def decay2(t,a1,t1,a2,t2):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    e2 = a2*np.exp(-t/t2)\n",
    "    return e1+e2\n",
    "\n",
    "def intdec2(t,a1,t1,a2,t2):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k1,k2  = -a1*t1, - a2*t2\n",
    "    \n",
    "    return k1*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) + k2*(np.exp(-tu/t2)-np.exp(-td/t2))/(tu-td)\n",
    "\n",
    "#Single exponential models plus a constant\n",
    "\n",
    "def intdec1_plusconst(t,a1,t1,q):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "    k  = -a1*t1\n",
    "    return k*(np.exp(-tu/t1)-np.exp(-td/t1))/(tu-td) +q\n",
    "\n",
    "def dec1_plusconst(t,a1,t1,q):\n",
    "    e1 = a1*np.exp(-t/t1)\n",
    "    return e1+q\n",
    "\n",
    "\n",
    "#Shifted power law model\n",
    "\n",
    "def shpwl(t,t0,A,index):\n",
    "    return A * ((t+t0)/1000)**index\n",
    "\n",
    "def intshpwl(t,t0,A,index):\n",
    "    tu = t[1:]\n",
    "    td = t[:-1]\n",
    "\n",
    "    if (index == -1.):\n",
    "        return A*np.log( (tu+t0)/(td+t0) )\n",
    "    else:\n",
    "        return A/(1+index) * ( ((tu+t0)/1000)**(1+index) - ((td+t0)/1000)**(1+index) )/(tu-td)\n",
    "    \n",
    "    \n",
    "#Schechter like model\n",
    "\n",
    "def schechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "    return phi*(x**alpha)*np.exp(-x)\n",
    "\n",
    "def intschechter(t,phi,alpha,tstar):\n",
    "    x = t/tstar\n",
    "\n",
    "    tu = x[1:]\n",
    "    td = x[:-1]\n",
    "\n",
    "    g1 = gammaincc(alpha+1,td)\n",
    "    g2 = gammaincc(alpha+1,tu)\n",
    "    \n",
    "    diff = gamma(alpha+1)*(g1-g2)\n",
    "    \n",
    "    return phi*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Geometric median calculation function\n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1, D\n",
    "\n",
    "        y = y1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read files, make sure they are sorted by EXPSTART\n",
    "\n",
    "sflts= []\n",
    "\n",
    "for vis in ['1','2','3']:\n",
    "    wdir = pdir+'/14016_data/Visit0'+vis+'/'\n",
    "    flts = glob.glob(wdir+'*_flt.fits')\n",
    "    print('***************')\n",
    "    starttimes = []\n",
    "    endtimes   = []\n",
    "    imagetypes = []\n",
    "    for flt in flts:\n",
    "        starttimes.append(fits.getheader(flt,0)['EXPSTART'])\n",
    "        endtimes.append(fits.getheader(flt,0)['EXPEND'])\n",
    "        imagetypes.append(fits.getheader(flt,0)['IMAGETYP'])\n",
    "    \n",
    "    ii = np.argsort(starttimes)\n",
    "    for jj in range(len(flts)):\n",
    "        print(starttimes[ii[jj]],endtimes[ii[jj]],(starttimes[ii[jj]]-endtimes[ii[jj]])*24*3600,imagetypes[ii[jj]],flts[ii[jj]])\n",
    "\n",
    "\n",
    "    sflts.append([flts[i] for i in ii])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose which visit to work on\n",
    "\n",
    "visit_index = 0\n",
    "vsflts = sflts[visit_index]\n",
    "\n",
    "# If in a hurry, shorten the list for faster analysis\n",
    "\n",
    "vsflts = vsflts[0:10]\n",
    "\n",
    "#plot all exposures multiple times for visualization of the selected pixels\n",
    "\n",
    "sf=1.5\n",
    "fig = plt.figure(figsize=(sf*len(vsflts),sf*len(vsflts)))\n",
    "\n",
    "ax = []\n",
    "for i,flt in enumerate(vsflts):\n",
    "    im = fits.getdata(flt)\n",
    "    c, low, upp = sigmaclip(im, 2.5,3)\n",
    "    mn = np.amin(c)\n",
    "    print(flt,'clipped mean: ',mn)\n",
    "    j = -1\n",
    "    while j < i: \n",
    "        j+=1\n",
    "        ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1+i))\n",
    "        ax[-1].imshow(np.log10(im-mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "        ax[-1].set_title(flt[-18:-9],fontsize=6)\n",
    "        ax[-1].get_xaxis().set_ticks([])\n",
    "        ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "        \n",
    "# Read the mosaic file and plot it\n",
    "\n",
    "plt.tight_layout()\n",
    "mosaic = fits.open(mdir+'/F140W_Mosaic_WFC3_IR_drz.fits')\n",
    "\n",
    "ax.append(plt.subplot(len(vsflts),len(vsflts),j*len(vsflts)+1))\n",
    "\n",
    "pos1 = ax[-1].get_position() # get the original position \n",
    "pos2 = [pos1.x0, pos1.y0,  pos1.width * len(vsflts)/2., pos1.height * len(vsflts)/2.] \n",
    "ax[-1].set_position(pos2) # set a new position\n",
    "ax[-1].get_xaxis().set_ticks([])\n",
    "ax[-1].get_yaxis().set_ticks([])\n",
    "        \n",
    "c, low, upp = sigmaclip(mosaic[1].data[np.where(np.isfinite(mosaic[1].data))], 2.5,3)\n",
    "mn = np.amin(c)\n",
    "im = ax[-1].imshow(np.log10(mosaic[1].data-mn),cmap='viridis', interpolation='none', origin='lower')\n",
    "ax[-1].set_title('Drizzled \\n mosaic',fontsize=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create the wcs objects for the AD mosaic and flts \n",
    "\n",
    "w_mosaic = WCS(mosaic[1].header)\n",
    "\n",
    "w_vsflts = []\n",
    "for vsflt in vsflts:\n",
    "    w_vsflts.append(WCS(fits.getheader(vsflt,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes the vsflts list, the current flt that is being used as stimulus\n",
    "# and looks for all the pixels with valid stimulus values AND that have valid ramps (i.e. no source, only sky)\n",
    "# in the following exposures AND that where not stimulated more than 10% of the current stimulus in \n",
    "# ANY past exposure\n",
    "\n",
    "def find_ramps(istim,flts,lev_u,lev_d):\n",
    "    \n",
    "    stimdata  = flts[istim,:,:]\n",
    "    istimgood = (stimdata > lev_d) & (stimdata < lev_u)  \n",
    "    print('Pixels with potentially right stimuli:',np.sum(istimgood) )\n",
    "\n",
    "    \n",
    "    for i in range(istim):\n",
    "        persdata = flts[i,:,:]       \n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            istimgood = istimgood & (persdata < 0.1*stimdata) \n",
    "            \n",
    "    print('Pixels with really right stimuli:',np.sum(istimgood) )\n",
    "    \n",
    "    \n",
    "    icount    = np.zeros_like(stimdata,dtype=np.int_)\n",
    "    iprev     = istimgood\n",
    "    for i in range(istim+1,len(imtyps),1):\n",
    "    \n",
    "        persdata = flts[i,:,:]\n",
    "    \n",
    "        if (imtyps[i] == 'EXT'):\n",
    "            msky = np.nanmean(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            ssky = np.nanstd(sigmaclip(persdata,2.5,2.5)[0])\n",
    "            iskycurr = (persdata <msky+1*ssky) & (persdata >msky-1*ssky)    \n",
    "        elif (imtyps[i] == 'DARK'):\n",
    "            iskycurr = np.ones_like(persdata,dtype=np.bool_)\n",
    "        else:\n",
    "            print('Wrong image type')\n",
    "            assert False\n",
    "        \n",
    "        igood = istimgood & iskycurr & iprev\n",
    "        iprev = igood\n",
    "        icount[igood] += 1\n",
    "\n",
    "        print('Pixels with ramps extending for at least',i-istim,' exposures:', igood.sum())\n",
    "        \n",
    "        if (np.sum(igood) == 0):\n",
    "            break\n",
    "                 \n",
    "    return icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dedfine a function to get the sky value in the cureent flt pixel, but measured form the AD mosaic\n",
    "\n",
    "def getskyfrommosaic(wcsAD, wcsFLT, x, y, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic):\n",
    "\n",
    "    coords = wcsAD.all_world2pix(wcsFLT.all_pix2world(np.array([[x,y]],dtype=np.float_),0),0) \n",
    "    dx = coords[0,0]\n",
    "    dy = coords[0,1]\n",
    "    \n",
    "    dst = np.sqrt((dxgrid-dx)**2 + (dygrid-dy)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i) & mask_sky_contam \n",
    "    skyarr = mosaic[1].data[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n",
    "# Similar but for darks\n",
    "\n",
    "def getbackgroundfordarks (x, y, xgrid, ygrid, skyrad_o,skyrad_i, fltdata):\n",
    "\n",
    "    dst = np.sqrt((xgrid-x)**2 + (ygrid-y)**2)\n",
    "    msk = (dst<skyrad_o) & (dst > skyrad_i)\n",
    "    skyarr = fltdata[msk]\n",
    "    cskyarr,l,u = sigmaclip(skyarr,2.,2.)\n",
    "    return np.nanmean(cskyarr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the numpy arrays containg the iam and flt data as well\n",
    "# as the arrays of metadata\n",
    "\n",
    "ima_scis  = []\n",
    "ima_errs  = []\n",
    "ima_times = [] \n",
    "flts      = []\n",
    "tendMJDs  = []\n",
    "tstrMJDs  = []\n",
    "imtyps    = []\n",
    "nsamps    = []\n",
    "sampseqs = []\n",
    "\n",
    "for vsflt in vsflts:\n",
    "    print('Appending '+vsflt+' to the datacube')\n",
    "    ima = fits.open(vsflt.replace('_flt','_ima'))\n",
    "    nsamps.append(ima[0].header['NSAMP'])\n",
    "    sampseqs.append(ima[0].header['SAMP_SEQ'])\n",
    "    for k in range(nsamps[-1]):\n",
    "        \n",
    "        ima_scis.append(ima['SCI',k+1].data[5:-5,5:-5])\n",
    "        ima_errs.append(ima['ERR',k+1].data[5:-5,5:-5])\n",
    "        ima_times.append(ima['TIME',k+1].header['PIXVALUE'])\n",
    "      \n",
    "    flt = fits.open(vsflt)\n",
    "    flts.append(flt[1].data)\n",
    "    \n",
    "    tendMJDs.append(flt[0].header['EXPEND'])\n",
    "    tstrMJDs.append(flt[0].header['EXPSTART'])\n",
    "    imtyps.append(flt[0].header['IMAGETYP'])\n",
    "    flt.close()\n",
    "    ima.close()\n",
    "\n",
    "ima_scis  = np.asarray(ima_scis)\n",
    "ima_errs  = np.asarray(ima_errs)\n",
    "ima_times = np.asarray(ima_times)\n",
    "flts      = np.asarray(flts)\n",
    "tendMJDs  = np.asarray(tendMJDs)\n",
    "tstrMJDs  = np.asarray(tstrMJDs)\n",
    "imtyps    = np.asarray(imtyps)\n",
    "nsamps    = np.asarray(nsamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_sky_and_indices(nz0, nz1, j, istim):\n",
    "    # Function to get the sky value, as well as calculate the indices needed in the large data cube of IMA reads\n",
    "       \n",
    "    #Get the sky from the drizzled image\n",
    "    imtyp = imtyps[istim+j]\n",
    "\n",
    "    if(imtyp == 'EXT'):\n",
    "        skyhere = getskyfrommosaic(w_mosaic, w_vsflts[istim+j], nz1, nz0, dxgrid, dygrid, skyrad_o,skyrad_i,mask_sky_contam,mosaic)\n",
    "    elif(imtyp == 'DARK'):\n",
    "        skyhere = getbackgroundfordarks(nz1, nz0, xgrid, ygrid, skyrad_o,skyrad_i, flts[istim+j,:,:])\n",
    "    else:\n",
    "        print('Wrong image type')\n",
    "        assert False\n",
    "    \n",
    "    offset = ( tstrMJDs[istim+j] - tendMJDs[istim])*24.*60*60\n",
    "    ioff = np.sum(nsamps[0:istim+j])\n",
    "    nsamp = nsamps[istim+j]\n",
    "    \n",
    "    k_product = product([nz0], [nz1], [skyhere], [offset], [ioff], [nsamp], [j], range(nsamp-1))\n",
    "    return list(k_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(inputs, index, istim):\n",
    "    # # function to extract the values from the IMA cube and IMA metadata arrays\n",
    "    \n",
    "    nz1, nz0, skyhere, offset, ioff, nsamp, j, k = inputs\n",
    "    #ll = index\n",
    "    te = ima_times[ioff+k]\n",
    "    ts = ima_times[ioff+k+1]\n",
    "\n",
    "    tfromstim = te + offset\n",
    "\n",
    "    tdenom = te - ts  \n",
    "    meancurr  = (ima_scis[ioff+k,nz1,nz0]*te - ima_scis[ioff+k+1,nz1,nz0]*ts)/tdenom\n",
    "    stdvcurr  = np.sqrt(np.sum(np.square([ima_errs[ioff+k,nz1,nz0]*te,ima_errs[ioff+k+1,nz1,nz0]*ts])))/tdenom\n",
    "\n",
    "    \n",
    "    #storearr[ll,:] = [flts[istim,nz0,nz1],nz1,nz0,tfromstim,tdenom,nsamp-k-1,nsamp,meancurr,stdvcurr,skyhere,istim,istim+j]\n",
    "\n",
    "    #perc = 100.*(ll+1.)/(1.*nlines)\n",
    "    #if( ll%modulus ==0. ):\n",
    "    #    print(np.int(perc),'% done')\n",
    "        #print(storearr[ll,:])\n",
    "        \n",
    "    return [flts[istim,nz1,nz0],nz0,nz1,tfromstim,tdenom,nsamp-k-1,nsamp,meancurr,stdvcurr,skyhere,istim,istim+j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define the stimuli e-/s level to identify the ramps\n",
    "\n",
    "lev_u = np.inf\n",
    "lev_d = 3.5e4\n",
    "\n",
    "# Define the pixel grid (to trasform indices in x,y positions)\n",
    "xgrid,ygrid = np.meshgrid( np.arange(fits.getdata(vsflts[0],1).shape[1]) ,np.arange(fits.getdata(vsflts[0],1).shape[0]))\n",
    "dxgrid,dygrid = np.meshgrid( np.arange(mosaic[1].data.shape[1]) ,np.arange(mosaic[1].data.shape[0]))\n",
    "\n",
    "drz_fin = np.isfinite(mosaic[1].data)\n",
    "\n",
    "msky_d = np.nanmean(sigmaclip(mosaic[1].data[drz_fin],2.5,2.5)[0])\n",
    "ssky_d = np.nanstd(sigmaclip(mosaic[1].data[drz_fin],2.5,2.5)[0])\n",
    "mask_sky_contam = (mosaic[1].data <msky_d+3*ssky_d) & (mosaic[1].data >msky_d-3*ssky_d) & drz_fin\n",
    "\n",
    "skyrad_o = 25\n",
    "skyrad_i = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#before running the big step perform garbage collection\n",
    "gc.collect()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "cols = ['Stim','xpix','ypix','tfromstim','deltat','Read index','NSAMP','meancurr','stdvcurr','ADsky','Ind_stim','Ind_pers']\n",
    "\n",
    "mypool = Pool(4)\n",
    "\n",
    "# Parallelized version\n",
    "for istim,stim in enumerate(vsflts[:-1]):\n",
    "\n",
    "    print('**********************')\n",
    "    print('Doing: ',stim)\n",
    "\n",
    "    icount    = find_ramps(istim,flts,lev_u,lev_d)\n",
    "    \n",
    "    nz     = np.nonzero(icount)    \n",
    "    nnexts = icount[nz]\n",
    "    \n",
    "    nlines = 0.\n",
    "    for nnext in nnexts:\n",
    "        nlines = nlines+np.sum((nsamps-1)[istim+1:istim+1+nnext])\n",
    "\n",
    "    print('Number of entries: ',nlines)\n",
    "    modulus = np.trunc(nlines/10)\n",
    "    \n",
    "    if (nlines > 0) :\n",
    "        flt_big_index = []\n",
    "        for nz0,nz1,nnext in list(zip(nz[0],nz[1],nnexts)):\n",
    "            prod = product([nz0], [nz1], range(1,nnext+1,1),[istim])\n",
    "            flt_big_index += list(prod)\n",
    "    \n",
    "        derp = mypool.starmap(get_sky_and_indices, flt_big_index)\n",
    "        ima_big_index = []\n",
    "        for block in derp:\n",
    "            ima_big_index += block\n",
    "        \n",
    "        biglist = mypool.starmap(get_pixel_values,zip(ima_big_index,range(int(nlines)), [istim]*nlines))\n",
    "        df = df.append(pd.DataFrame(biglist,columns=cols))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with bz2.BZ2File(sdir+'Test_DF.pbz2', 'w') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gBMs    =   [np.ones(len(df),dtype=np.bool_)]\n",
    "gBMs.append( (df['Ind_pers'] != 7) )\n",
    "gBMs.append( (df['Ind_pers'] != 7) & (df['Read index'] != 1) )\n",
    "gBMs.append( (df['Ind_pers'] == 7) & (df['deltat'] > 10 ))\n",
    "gBMs.append( (df['Ind_pers'] > 7)  & (df['Read index'] != 1) )\n",
    "gBMs.append( (df['Ind_pers'] < 7)  & (df['Read index'] != 1) )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,4*len(gBMs)))\n",
    "ax = []\n",
    "\n",
    "for i,gBM in enumerate(gBMs):\n",
    "\n",
    "    df2 = df[gBM]\n",
    "\n",
    "    ax.append(fig.add_subplot(len(gBMs),2,1+i*2))\n",
    "    ax.append(fig.add_subplot(len(gBMs),2,2+i*2))\n",
    "        \n",
    "    ax[-2].scatter(df2['tfromstim'],df2['meancurr']-df2['ADsky'],s=2,alpha=0.7)\n",
    "    ax[-1].scatter(df2['tfromstim'],df2['meancurr']-df2['ADsky'],s=2,alpha=0.7)\n",
    "\n",
    "    step = 25.\n",
    "    tmin = np.min(df2['tfromstim'].values)\n",
    "    tmax = np.max(df2['tfromstim'].values)\n",
    "\n",
    "    tmed   = []\n",
    "    medsig = []\n",
    "\n",
    "    while tmin <= tmax:\n",
    "\n",
    "        BM =  (df2['tfromstim'].values > tmin-step/2.) & (df2['tfromstim'].values <= (tmin+ step/2.))\n",
    "        tmin += step\n",
    "        if (np.sum(BM) > 5):\n",
    "            tmed.append(np.median(df2['tfromstim'][BM]))\n",
    "            medsig.append(np.nanmedian(sigmaclip((df2['meancurr'][BM].values-df2['ADsky'][BM].values),2.5,2.5)[0]))\n",
    "    \n",
    "    ax[-2].plot(tmed,medsig,c='r')\n",
    "    ax[-1].plot(tmed,medsig,c='r')               \n",
    "    \n",
    "    ax[-1].set_xscale('log')\n",
    "    ax[-1].set_yscale('log')\n",
    "    ax[-1].set_ylim(0.001,30)\n",
    "    ax[-2].set_ylim(-20,30)\n",
    "    ax[-1].set_xlim(0,10000)\n",
    "    ax[-2].set_xlim(0,10000)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gstims = np.unique(df['Ind_stim'] )\n",
    "\n",
    "fig = plt.figure(figsize=(15,4*gstims.size))\n",
    "\n",
    "ax = []\n",
    "\n",
    "for j,i in enumerate(gstims):\n",
    "    gBMh = (df['Ind_stim'] == i) & (df['Ind_pers'] != 7) & (df['Read index'] != 1)\n",
    "    \n",
    "    \n",
    "    if (np.sum(gBMh) > 0):\n",
    "        df2 = df[gBMh]\n",
    "        ax.append(fig.add_subplot(gstims.size,2,j*2+1))\n",
    "        ax.append(fig.add_subplot(gstims.size,2,j*2+2))\n",
    "\n",
    "        ax[-2].scatter(df2.tfromstim,df2.meancurr-df2.ADsky,s=2,alpha=0.7)\n",
    "        ax[-1].scatter(df2.tfromstim,df2.meancurr-df2.ADsky,s=2,alpha=0.7)\n",
    "\n",
    "        tmedh = []\n",
    "        medsigh= []\n",
    "        tmin = np.min(df2.tfromstim.values)\n",
    "        tmax = np.max(df2.tfromstim.values)\n",
    "\n",
    "        while tmin <= tmax:\n",
    "    \n",
    "            BM =  (df2.tfromstim.values > tmin-step/2.) & (df2.tfromstim.values <= (tmin+ step/2.))\n",
    "            tmin += step\n",
    "            if (np.sum(BM) > 3):\n",
    "                tmedh.append(np.median(df2[BM].tfromstim))\n",
    "                medsigh.append(np.nanmedian(sigmaclip((df2[BM].meancurr.values-df2[BM].ADsky.values),2.5,2.5)[0]))\n",
    "    \n",
    "        ax[-2].plot(tmed,medsig,c='r')\n",
    "        ax[-1].plot(tmed,medsig,c='r')\n",
    "        ax[-2].plot(tmedh,medsigh,c='orange')\n",
    "        ax[-1].plot(tmedh,medsigh,c='orange')\n",
    "    else:\n",
    "        ax[-2].plot(tmed,medsig,c='r')\n",
    "        ax[-1].plot(tmed,medsig,c='r')\n",
    "  \n",
    "    ax[-1].set_xscale('log')\n",
    "    ax[-1].set_yscale('log')\n",
    "    ax[-1].set_ylim(0.001,30)\n",
    "    ax[-2].set_ylim(-20,30)\n",
    "    ax[-1].set_xlim(0,10000)\n",
    "    ax[-2].set_xlim(0,10000)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
